{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178c2388",
   "metadata": {},
   "source": [
    "# Closed Form Linear Regression\n",
    "\n",
    "This project demonstrates the application of closed form linear regression on the insurance dataset. The goal is to predict insurance charges based on various features such as age, sex, BMI, number of children, smoking status, and region. The notebook includes preprocessing steps, training and testing the model, and performing cross-validation.\n",
    "\n",
    "# Setup\n",
    "\n",
    "We start by importing the necessary libraries and setting a fixed random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5486b439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:43:54.739187Z",
     "start_time": "2023-10-24T23:43:54.724318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca203f",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this section, we will analyze the dataset, preprocess the variables, and prepare the data for model training. We will convert categorical variables to numerical values, perform one-hot encoding where necessary, and ensure the data is shuffled and split into training and testing sets. First, let's load the dataset and take a look at its structure to understand the data we're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e610905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:43:55.782785Z",
     "start_time": "2023-10-24T23:43:55.758410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd0eff",
   "metadata": {},
   "source": [
    "We have the following columns in our dataset:\n",
    "\n",
    "- **age**: Age of the individual\n",
    "- **sex**: Gender of the individual (male/female)\n",
    "- **bmi**: Body Mass Index of the individual\n",
    "- **children**: Number of children the individual has\n",
    "- **smoker**: Smoking status of the individual (yes/no)\n",
    "- **region**: Region where the individual resides (northeast/northwest/southeast/southwest)\n",
    "- **charges**: Medical insurance charges billed to the individual\n",
    "\n",
    "\n",
    "Next, we preprocess the variables and the dataframe, making it suitable for our regression model. We do the following preprocessing steps:\n",
    "1. Convert `sex` and `smoker` columns to binary values.\n",
    "2. Perform one-hot encoding on the `region` column.\n",
    "3. Ensure all columns are of type float for processing.\n",
    "4. Shuffle the dataset to ensure randomness.\n",
    "5. Reset the index to maintain a clean index order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46601d52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:43:56.521148Z",
     "start_time": "2023-10-24T23:43:56.509217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert sex, smoker to binary\n",
    "df['sex'] = df['sex'].replace({'male': 1, 'female': 0})\n",
    "df['smoker'] = df['smoker'].replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# One-hot encode the region column and concatenate to original df\n",
    "df = pd.get_dummies(df, columns=['region'], prefix='', prefix_sep='')\n",
    "\n",
    "# Convert all columns to float for processing\n",
    "df = df.astype(float)\n",
    "\n",
    "# Shuffle rows\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f73f40",
   "metadata": {},
   "source": [
    "We now separate the target variable (`charges`) from the features and add a dummy variable to the features to account for the bias term in the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80c7e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:43:57.416428Z",
     "start_time": "2023-10-24T23:43:57.397561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate charges column as y value to predict\n",
    "y = df['charges']\n",
    "\n",
    "# Drop 'charges', add dummy variable to df first column and get feature matrix X\n",
    "x = df.drop('charges', axis=1).assign(dummy=np.ones(df.shape[0]))[['dummy'] + df.drop('charges', axis=1).columns.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2951723",
   "metadata": {},
   "source": [
    "We now split the data into training and testing sets. This will allow us to train the model on one subset of the data and validate it on another to ensure that it generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdf2fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:43:58.248505Z",
     "start_time": "2023-10-24T23:43:58.235176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=(1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518ebe7",
   "metadata": {},
   "source": [
    "\n",
    "Once we have our training and test/validation sets ready, we can move onto training and evaluating our model\n",
    "\n",
    "# Model Training and Evaluation\n",
    "\n",
    "We begin by calculating the weight vector using the closed form solution of linear regression on the training set. The training set is used for this computation to fit the model parameters without bias from the unseen test data. This approach ensures that the model learns only from the training data, which is crucial for evaluating its performance objectively on the validation or test set later. The closed form solution for the weight vector $ \\mathbf{w} $ in linear regression is given by:\n",
    "\n",
    "$$\n",
    "[\n",
    "\\mathbf{w} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "]\n",
    "$$\n",
    "where:\n",
    "- $ \\mathbf{X} $ is the matrix of input features (with a column of ones for the intercept term),\n",
    "- $ \\mathbf{y} $  is the vector of target values (charges in this case),\n",
    "- $ \\mathbf{X}^\\top $ is the transpose of $ \\mathbf{X} $, \n",
    "- $(\\mathbf{X}^\\top \\mathbf{X})^{-1} $ is the inverse of the matrix $ \\mathbf{X}^\\top \\mathbf{X} $.\n",
    "\n",
    "By using this equation, we can directly compute the optimal weight vector that minimizes the sum of squared errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "286e3bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:43:59.678826Z",
     "start_time": "2023-10-24T23:43:59.660658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate weight vector using closed form solution\n",
    "w = np.dot(np.linalg.pinv(np.dot(x_train.T, x_train)), np.dot(x_train.T, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab4097a-6274-4ebb-8033-ac35a52d82ff",
   "metadata": {},
   "source": [
    "The calculated weight vector $ \\mathbf{w} $ can now be used to make predictions on both the training and validation datasets. This step involves taking the dot product of the input features $ \\mathbf{X} $ with the weight vector to estimate the insurance charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f847c175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:44:06.172394Z",
     "start_time": "2023-10-24T23:44:06.155083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictions on training set\n",
    "y_train_pred = np.dot(x_train, w)\n",
    "\n",
    "# Predictions on validation set\n",
    "y_val_pred = np.dot(x_val, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ed4d5-f68c-4350-b778-8a2ce89fbb36",
   "metadata": {},
   "source": [
    "We then use the Root-Mean Squared Error (RMSE) as one of our evaluation metrics. RMSE is a standard way to measure the error of a model in predicting quantitative data. It represents the square root of the average of the squared differences between actual and predicted values. The formula for RMSE is:\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "where $ y_i $ are the actual values and $ \\hat{y}_i $ are the predicted values, and $ n $ is the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b6de204-5639-4c04-9bdd-875a5052f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE for training set\n",
    "rmse_train = (sum((y_train - y_train_pred)**2)/len(y_train))**0.5;\n",
    "\n",
    "# RMSE for validation set\n",
    "rmse_val = (sum((y_val - y_val_pred)**2)/len(y_val))**0.5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047fce5",
   "metadata": {},
   "source": [
    "\n",
    "SMAPE is another robust measure of forecasting accuracy that we use. It scales the absolute percentage error by the sum of the absolute values of the actual and predicted values, which mitigates issues when the actual values are close to zero. The formula for SMAPE is:\n",
    "\n",
    "$$\n",
    "\\text{SMAPE} = \\frac{100\\%}{n} \\sum_{i=1}^n \\frac{|y_i - \\hat{y}_i|}{\\frac{(|y_i| + |\\hat{y}_i|)}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b31f979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:44:08.023311Z",
     "start_time": "2023-10-24T23:44:07.860248Z"
    }
   },
   "outputs": [],
   "source": [
    "# SMAPE for training set\n",
    "smape_train = sum((abs(y_train - y_train_pred))/(abs(y_train) + abs(y_train_pred)))/len(y_train);\n",
    "\n",
    "# SMAPE for validation set\n",
    "smape_val = sum((abs(y_val - y_val_pred))/(abs(y_val) + abs(y_val_pred)))/len(y_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae367a38",
   "metadata": {},
   "source": [
    "Finally, we print the calculated RMSE and SMAPE values for both training and validation sets to assess the performance of our linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6b2940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:44:26.895894Z",
     "start_time": "2023-10-24T23:44:19.068140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 5947.21, Validation RMSE: 6254.90\n",
      "Training SMAPE: 18.61%, Validation SMAPE: 21.24%\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(f\"Training RMSE: {rmse_train:.2f}, Validation RMSE: {rmse_val:.2f}\")\n",
    "print(f\"Training SMAPE: {smape_train:.2%}, Validation SMAPE: {smape_val:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e132ac2",
   "metadata": {},
   "source": [
    "\n",
    "The RMSE and SMAPE values indicate our model performs consistently between training and validation sets, with a slightly better accuracy on the validation set. This suggests good generalization. However, to further confirm these results and ensure the model's robustness, we'll next employ cross-validation across different data subsets.\n",
    "\n",
    "# Cross-Validation\n",
    "\n",
    "Cross-validation is a robust statistical method used to estimate the accuracy of predictive models. It helps to mitigate overfitting by using different subsets of the data for training and validating the model multiple times. This process enhances the generalizability of the model as it must perform well on multiple different data splits to achieve a low average error.\n",
    "\n",
    "In our implementation, we use a function to automate the cross-validation process with variable numbers of folds, $ S $. This function:\n",
    "- Randomly shuffles the dataset.\n",
    "- Splits the dataset into $ S $ distinct folds.\n",
    "- Iteratively uses one fold for validation and the remainder for training.\n",
    "- Computes the root mean square error (RMSE) for each fold.\n",
    "- Calculates and prints the mean and standard deviation of the RMSE across all folds to provide a comprehensive view of the model's performance stability across different subsets of data.\n",
    "\n",
    "This method ensures each data point gets used for both training and validation, and the mean RMSE across folds gives us a robust measure of our model's predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2c0ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T23:45:19.212418Z",
     "start_time": "2023-10-24T23:44:32.503559Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_validation(df, S, num_seeds=20):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the dataset to evaluate the model performance.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataset containing features and the target variable.\n",
    "        S (int): The number of folds for cross-validation.\n",
    "        num_seeds (int): The number of random seeds to use for averaging the results.\n",
    "\n",
    "    Prints:\n",
    "        The mean and standard deviation of the RMSE across all seeds.\n",
    "    \"\"\"\n",
    "    rmse_vals = []  # List to store RMSE values for each seed\n",
    "\n",
    "    for seed in range(num_seeds):\n",
    "        np.random.seed(seed)  # Set the seed for reproducibility\n",
    "        currdf = df.sample(frac=1)\n",
    "\n",
    "        # Reset the index\n",
    "        currdf.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        currdf.insert(0, 'dummy', np.ones(len(currdf)))  # Add a dummy variable for intercept\n",
    "\n",
    "        # Declare variable to hold total sum of se values over different folds\n",
    "        se_foldSum = 0;\n",
    "\n",
    "        for i in range(S):\n",
    "            # Get rows for training and validation\n",
    "            row_train = currdf.index[currdf.index % S != i].tolist()\n",
    "            row_val = currdf.index[currdf.index % S == i].tolist()\n",
    "            \n",
    "            \n",
    "            # Split into train and test set\n",
    "            training_data = currdf.loc[row_train]\n",
    "            validation_data = currdf.loc[row_val]\n",
    "            \n",
    "            # Set x and y separate\n",
    "            y_train = training_data['charges'];\n",
    "            y_val = validation_data['charges'];\n",
    "            x_train = training_data.drop('charges', axis=1);\n",
    "            x_val = validation_data.drop('charges', axis=1);\n",
    "            \n",
    "            # Calculate w\n",
    "            w = np.dot(np.linalg.pinv(np.dot(x_train.T,x_train)),np.dot(x_train.T,y_train));\n",
    "            \n",
    "            # Train the validation set\n",
    "            y_val_pred = np.dot(x_val, w)\n",
    "            \n",
    "            # Get SE values\n",
    "            se_val = (y_val - y_val_pred)**2;\n",
    "            \n",
    "            # Sum all se values in vector\n",
    "            se_sum = np.sum(se_val);\n",
    "            \n",
    "            # Add to total sum over folds\n",
    "            se_foldSum = se_foldSum + se_sum\n",
    "                \n",
    "        # Calculate RMSE for current seed\n",
    "        currRmse = ((se_foldSum)/(currdf.shape[0]))**0.5\n",
    "        \n",
    "        # Append to all RMSE values     \n",
    "        rmse_vals.append(currRmse);\n",
    "\n",
    "    # Output the mean and standard deviation of the RMSE across all seeds\n",
    "    print(f\"Mean RMSE for S = {S}: {np.mean(rmse_vals)}\")\n",
    "    print(f\"Standard Deviation for S = {S}: {np.std(rmse_vals)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8ec19-30cf-4140-942c-c1a867d51993",
   "metadata": {},
   "source": [
    "We then test our model with a smaller number of folds (S = 3) allows for a quick evaluation and provides a basic understanding of the model's performance across different subsets of data. This setup will likely give us a preliminary indication of the model's stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02d0ccce-969a-4a42-9f7d-19a7bf3e800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for S = 3: 6105.729170235434\n",
      "Standard Deviation for S = 3: 24.221902629667582\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation with 3 folds\n",
    "cross_validation(df, S=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e198df1-269e-40a6-b383-d84afc7ee23d",
   "metadata": {},
   "source": [
    "The mean RMSE of 6105.73 and the standard deviation of 24.22 indicate a reasonably consistent performance across different folds, though the prediction error is relatively high. To gain a more detailed understanding of the model's performance, we will now increase the number of folds to 223."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "995e7042-8bf2-4caa-9ccd-61609570e6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for S = 223: 6087.04528906167\n",
      "Standard Deviation for S = 223: 1.2257337663619199\n"
     ]
    }
   ],
   "source": [
    "cross_validation(df, S=223)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fca252-1e0d-4d1f-8c86-d4dc42087c06",
   "metadata": {},
   "source": [
    "The mean RMSE of 6087.05 and the significantly lower standard deviation of 1.23 demonstrate that the model benefits from finer segmentation of the dataset. This setup leads to reduced prediction errors and more consistent performance. To further refine our assessment, we will now conduct leave-one-out cross-validation (LOOCV) with S equal to the number of data points, N = 1338."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37164514-9898-4d63-aacd-5e6071c21750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE for S = 1338: 6087.388006550289\n",
      "Standard Deviation for S = 1338: 2.0463630789890885e-11\n"
     ]
    }
   ],
   "source": [
    "cross_validation(df, S=1338)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256fb97-e2ff-4a5a-acb1-11d8f42b42b5",
   "metadata": {},
   "source": [
    "The mean RMSE of 6087.39 and the near-zero standard deviation indicate that the model performs consistently across all individual data points. This consistency demonstrates the model's robustness and reliability in predicting insurance charges, making it a strong candidate for practical applications.\n",
    "\n",
    "# Contact\n",
    "\n",
    "**Prepared by:** Farzan Mirza\n",
    "\n",
    "**Email:** [farzanmrz@gmail.com](mailto:farzanmrz@gmail.com), [fm474@drexel.edu](mailto:fm474@drexel.edu)\n",
    "\n",
    "**GitHub:** [https://github.com/Farzanmrz](https://github.com/Farzanmrz)\n",
    "\n",
    "**LinkedIn:** [https://www.linkedin.com/in/farzan-mirza13/](https://www.linkedin.com/in/farzan-mirza13/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "932.222px",
    "left": "75px",
    "top": "-0.425347px",
    "width": "383.976px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
